{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Myelin Mapping Notebook\n",
    "\n",
    "These workflows process T1 and T2 weighted images to then be used to quantify cortical myelin content per methods described in Gordon et al., 2017 (doi: 10.1016/j.neuron.2017.07.011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all othe functions/nodes being used\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber, FreesSurferSource\n",
    "from nipype.interfaces.fsl import FSLCommand, BET, Reorient2Std, FAST\n",
    "from nipype.interfaces.freesurfer import BBRegister, Binarize, ReconAll\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from pandas import read_csv\n",
    "\n",
    "# Declare study-specific variables\n",
    "setup='Cat'\n",
    "\n",
    "if setup=='Jay':\n",
    "    study_home = '/Users/dendrite/Desktop/Jay'\n",
    "    raw_data = study_home + '/raw'\n",
    "elif setup=='Cat':\n",
    "    study_home = '/moochie/user_data/CamachoCat/5YOP'\n",
    "    raw_data = '/moochie/study_data/5YOP/MRI_processing'\n",
    "    temp_fs_dir = '/home/camachocm2/Analysis/5YOP/freesurfer'\n",
    "    \n",
    "output_dir = study_home + '/proc'\n",
    "workflow_dir = study_home + '/workflows'\n",
    "fs_dir = study_home + '/freesurfer'\n",
    "\n",
    "session_info = read_csv(study_home + '/misc/session_info.csv',index_col=None)\n",
    "\n",
    "subject_ids = session_info['subject_id'].unique().tolist()\n",
    "subject_ids = map(str,subject_ids)\n",
    "\n",
    "# Set any processing settings\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subject_ids)\n",
    "\n",
    "# Selectfiles node to grab subject T2w data\n",
    "t2w_templates = {'T2anat': raw_data + '/{subject_id}/ANAT_NIFTIS/t2w_2.nii.gz'}\n",
    "t2w_source = Node(SelectFiles(t2w_templates), name='t2w_source')\n",
    "\n",
    "# datasink node\n",
    "datasink = Node(DataSink(base_directory=output_dir), name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess T1w data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab raw T1-weighted images and process through freesurfer\n",
    "t1w_template = {'t1_anats':raw_data + '/%s/ANAT_NIFTIS/t1w_*.nii.gz'}\n",
    "t1w_source = Node(DataGrabber(base_directory = raw_data, \n",
    "                              field_template = t1w_template,\n",
    "                              template=raw_data + '/%s/ANAT_NIFTIS/t1w_*.nii.gz',\n",
    "                              sort_filelist=True,\n",
    "                              in_fields=['subject_id'],\n",
    "                              outfields=['t1_anats'],\n",
    "                              template_args={'t1_anats':[['subject_id']]}), \n",
    "                  name='t1w_source')\n",
    "\n",
    "#process through recon-all\n",
    "reconall = Node(ReconAll(directive='all',flags='-gcut',openmp=4,\n",
    "                         subjects_dir=temp_fs_dir,use_T2=True), name='reconall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_proc = Workflow(name='freesurfer_proc_flow')\n",
    "fs_proc.connect([(infosource, t1w_source, [('subject_id','subject_id')]),\n",
    "                 (infosource, t2w_source, [('subject_id','subject_id')]),\n",
    "                 (infosource, reconall, [('subject_id','subject_id')]),\n",
    "                 (t1w_source, reconall, [('t1_anats','T1_files')]), \n",
    "                 (t2w_source, reconall, [('T2anat','T2_file')])\n",
    "                ])\n",
    "fs_proc.base_dir = workflow_dir\n",
    "fs_proc.write_graph(graph2use='flat')\n",
    "fs_proc.run('MultiProc', plugin_args={'n_procs': 10, 'memory_gb': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess T2w data\n",
    "The nodes and workflow below preprocess T2-weighted images to match T1-weighted data processed externally using FreeSurfer v6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to quantify T1/T2 ratio\n",
    "def quantify_ratio(T2_nifti)\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import divide, zeros\n",
    "    \n",
    "    #import images\n",
    "    t1w_img = import(FreeSurferSource(subject_dir=fs_dir), name='t1w_source')\n",
    "    t2w_img = import(T2_nifti)\n",
    "    t1w_data = t1w_img.get_data()\n",
    "    t2w_data = t2w_img.get_data()\n",
    "    \n",
    "    #calculate ratio and create new image\n",
    "    ratio = divide(t1w_data, t2w_data)\n",
    "    ratio_img = Nifti1Image(ratio, header=T2_nifti.header, affine=T2_nifti.affine)\n",
    "    save(ratio_img, 'ratio_image.nii.gz')\n",
    "    return ratio_img\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FreeSurferSource node to grab processed T1w data from freesurfer\n",
    "t1w_source = Node(FreeSurferSource(subject_dir=fs_dir), name='t1w_source')\n",
    "\n",
    "# skullstrip the T2w using BET (FSL)\n",
    "t2strip = Node(BET(), name='t2strip')\n",
    "\n",
    "# N4 bias correction of the T2w data (ANTs)\n",
    "bias_correct = Node(N4BiasFieldCorrection(),name='bias_correct')\n",
    "\n",
    "# Reorient T2w to standard\n",
    "reorient_t2w = Node(Reorient2Std(), name='reorient_t2w')\n",
    "\n",
    "# Register T2w to T1w using FreeSurfer's Boundary-Based Registration\n",
    "register = Node(BBRegister(subjects_dir = fs_dir, contrast_type='t2'), name='register')\n",
    "\n",
    "#Calculate T1/T2 ratio\n",
    "quantify_ratio = Node(Function(input_names=['T2_nifti'], \n",
    "                           output_names=['ratio_img'], \n",
    "                           function=quantify_ratio, name='quantify_ratio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Workflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-290ed24a36c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write the workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreprocess_t2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'preprocess_t2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m preprocess_t2.connect([(infosource, t1w_source, [('subject_id','subject_id')]),\n\u001b[1;32m      4\u001b[0m                        \u001b[0;34m(\u001b[0m\u001b[0minfosource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2w_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'subject_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0;34m(\u001b[0m\u001b[0minfosource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'subject_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Workflow' is not defined"
     ]
    }
   ],
   "source": [
    "# Write the workflow\n",
    "preprocess_t2 = Workflow(name='preprocess_t2')\n",
    "preprocess_t2.connect([(infosource, t1w_source, [('subject_id','subject_id')]),\n",
    "                       (infosource, t2w_source, [('subject_id','subject_id')]),\n",
    "                       (infosource, register, [('subject_id','subject_id')]),\n",
    "                       (t2w_source, t2strip,[('T2_anat','in_file')]),\n",
    "                       (t2strip, reorient_t2w,[('out_file','in_file')]),\n",
    "                       (reorient_t2w, bias_correct,[('out_file','input_image')]),\n",
    "                       (bias_correct, register,[('output_image','source_file')]),\n",
    "                       (bias_correct, quantify_ratio,[('output_image','T2_nifti')]),\n",
    "                       (t2strip, datasink,[('out_file','skullstripped_t2w')]),\n",
    "                       (register, datasink,[('registered_file','registered_t2w')])\n",
    "                       ])\n",
    "\n",
    "preprocess_t2.base_dir = workflow_dir\n",
    "preprocess_t2.write_graph(graph2use='flat')\n",
    "preprocess_t2.run('MultiProc', plugin_args={'n_procs': 2, 'memory_gb': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_surfs(surfs):\n",
    "    return(resampled_surfs)\n",
    "\n",
    "def volume_to_surface_myelin(volume):\n",
    "    return(surface_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform T2 surface registration and compute T1/T2 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
